{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gT70qr1SzoMF"
      },
      "source": [
        "**Semantic search**\n",
        "\n",
        "Using the latest insights from NLP research, it is possible to train a Language Model on a large corpus of documents. Afterwards, the model is able represent documents based on their “semantic” content. In particular, this includes the possibility to search for documents with semantically similar content.\n",
        "\n",
        "Semantic search means understanding the intent behind the query and representing the “knowledge in a way suitable for meaningful retrieval.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U7tOHZrszJk5",
        "outputId": "e3a01250-4e12-4066-c75e-6948b59f6c49"
      },
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install farasapy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YjF2ydoQsKpp",
        "outputId": "01a539bc-9f98-41d5-bdbe-ce10c6d1820e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting farasapy\n",
            "  Downloading farasapy-0.0.14-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from farasapy) (4.64.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from farasapy) (2.23.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->farasapy) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->farasapy) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->farasapy) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->farasapy) (3.0.4)\n",
            "Installing collected packages: farasapy\n",
            "Successfully installed farasapy-0.0.14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sS67K6kH2kXl"
      },
      "source": [
        "**Keyword Search Vs Semantic Search**\n",
        "\n",
        "At first, search engines were lexical: the search engine looked for literal matches of the query words, without understanding of the query’s meaning and only returning links that contained the exact query.By using regular keyword search, a document either contains the given word or not, and there is no middle ground On the other hand, \n",
        "\n",
        "**“Semantic** **Search”** can simplify query building, because it is supported by automated natural language processing programs i.e. using Latent Semantic Indexing — a concept that search engines use to discover how a keyword and content work together to mean the same thing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_Rn7svQ0Oms",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf8c11f3-b710-4188-8cdf-2a31add3e27c"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download(\"stopwords\")\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "data = pd.read_json('/content/drive/MyDrive/Freelancing/Project- 26/All_services_list_ar.json')\n",
        "# data = data[['name','unique_id','transaction_id','description','eligibility']]\n",
        "data.head(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "id": "zKQn8c32LEsx",
        "outputId": "ae6d651a-dc66-41ce-be02-72f7952e744a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        id                          name  \\\n",
              "0  3704682  طلب تجديد تصريح تعلم القيادة   \n",
              "\n",
              "                              parent_id transaction_id  unique_id  \\\n",
              "0  534a01e4-d350-453f-a035-decf9d67676b            786      70203   \n",
              "\n",
              "                                         description  \\\n",
              "0  تُمكِّنك هذه الخدمة من تجديد تصريح تعلُّم قياد...   \n",
              "\n",
              "                                         eligibility  \\\n",
              "0  يحقُّ للأفراد المواطنين والمقيمين الحصول على ه...   \n",
              "\n",
              "                              required_documents  \\\n",
              "0  <ol><li>الهوية الإماراتية الأصليّة.</li></ol>   \n",
              "\n",
              "                    average_waiting_time  \\\n",
              "0  <ul><li>10 دقائق كحدّ أقصى.</li></ul>   \n",
              "\n",
              "                                          output  ...  \\\n",
              "0  <p>تصريح تعلُّم قيادة المركبات المُجدَّد.</p>  ...   \n",
              "\n",
              "                                             process  \\\n",
              "0  <ul><li>يقدّم المتعامل الهوية الإماراتية الأصل...   \n",
              "\n",
              "                                      process_time related_documents  \\\n",
              "0  <ul><li>زيارة واحدة إلى معهد التعلّم.</li></ul>              null   \n",
              "\n",
              "                                                faqs apply_now_link  \\\n",
              "0  <ul><li><strong>السؤال الأول:</strong><span> ف...                  \n",
              "\n",
              "  most_popular service_classification disclaimer          updated_at  \\\n",
              "0        false         ترخيص السائقين            2021-10-22 06:20:31   \n",
              "\n",
              "                                            channels  \n",
              "0  [{'title': 'القنوات - الشركاء ومزودو الخدمات /...  \n",
              "\n",
              "[1 rows x 23 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e29c0f31-753a-4cb5-b6f4-3b9cac53f11d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>name</th>\n",
              "      <th>parent_id</th>\n",
              "      <th>transaction_id</th>\n",
              "      <th>unique_id</th>\n",
              "      <th>description</th>\n",
              "      <th>eligibility</th>\n",
              "      <th>required_documents</th>\n",
              "      <th>average_waiting_time</th>\n",
              "      <th>output</th>\n",
              "      <th>...</th>\n",
              "      <th>process</th>\n",
              "      <th>process_time</th>\n",
              "      <th>related_documents</th>\n",
              "      <th>faqs</th>\n",
              "      <th>apply_now_link</th>\n",
              "      <th>most_popular</th>\n",
              "      <th>service_classification</th>\n",
              "      <th>disclaimer</th>\n",
              "      <th>updated_at</th>\n",
              "      <th>channels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3704682</td>\n",
              "      <td>طلب تجديد تصريح تعلم القيادة</td>\n",
              "      <td>534a01e4-d350-453f-a035-decf9d67676b</td>\n",
              "      <td>786</td>\n",
              "      <td>70203</td>\n",
              "      <td>تُمكِّنك هذه الخدمة من تجديد تصريح تعلُّم قياد...</td>\n",
              "      <td>يحقُّ للأفراد المواطنين والمقيمين الحصول على ه...</td>\n",
              "      <td>&lt;ol&gt;&lt;li&gt;الهوية الإماراتية الأصليّة.&lt;/li&gt;&lt;/ol&gt;</td>\n",
              "      <td>&lt;ul&gt;&lt;li&gt;10 دقائق كحدّ أقصى.&lt;/li&gt;&lt;/ul&gt;</td>\n",
              "      <td>&lt;p&gt;تصريح تعلُّم قيادة المركبات المُجدَّد.&lt;/p&gt;</td>\n",
              "      <td>...</td>\n",
              "      <td>&lt;ul&gt;&lt;li&gt;يقدّم المتعامل الهوية الإماراتية الأصل...</td>\n",
              "      <td>&lt;ul&gt;&lt;li&gt;زيارة واحدة إلى معهد التعلّم.&lt;/li&gt;&lt;/ul&gt;</td>\n",
              "      <td>null</td>\n",
              "      <td>&lt;ul&gt;&lt;li&gt;&lt;strong&gt;السؤال الأول:&lt;/strong&gt;&lt;span&gt; ف...</td>\n",
              "      <td></td>\n",
              "      <td>false</td>\n",
              "      <td>ترخيص السائقين</td>\n",
              "      <td></td>\n",
              "      <td>2021-10-22 06:20:31</td>\n",
              "      <td>[{'title': 'القنوات - الشركاء ومزودو الخدمات /...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1 rows × 23 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e29c0f31-753a-4cb5-b6f4-3b9cac53f11d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e29c0f31-753a-4cb5-b6f4-3b9cac53f11d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e29c0f31-753a-4cb5-b6f4-3b9cac53f11d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7n7e9146Aec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "488cec40-79ab-48e4-f709-f3a6053af4dd"
      },
      "source": [
        "# !pip install spacy\n",
        "# !pip install requests --upgrade\n",
        "# !pip install git+https://github.com/ozgur/python-firebase\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "!pip install farasapy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "Requirement already satisfied: farasapy in /usr/local/lib/python3.7/dist-packages (0.0.14)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from farasapy) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from farasapy) (4.64.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->farasapy) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->farasapy) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->farasapy) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->farasapy) (3.0.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "import os\n",
        "import re\n",
        "# import preprocessor as p\n",
        "from nltk.corpus import stopwords,wordnet\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk import sent_tokenize, word_tokenize, pos_tag\n",
        "\n",
        "\n",
        "class CleaningText:\n",
        "\n",
        "    def __init__(self):\n",
        "        \n",
        "        self.punctuation = list(string.punctuation)\n",
        "        self.stop  = stopwords.words('english') + self.punctuation + ['rt', 'via', 'with', 'new', 'get', 'it', 'go',\"you\"]\n",
        "        \n",
        "        # self.pos_dict = {'J':wordnet.ADJ,'V':wordnet.VERB, 'N':wordnet.NOUN, 'R':wordnet.ADV}\n",
        "        self.not_stopwords = [\"not\", \"no\", \"neither\",\"don't\",\"wouldn't\",\"wouldn\",\"did'nt\",\n",
        "                         \"off\",\"didn't\",\"hadn't\",\"mightn't\",\"wasn't\",\"isn't\",\"couldn't\",\"shouldn't\", \"won't\",\"isn't\",\n",
        "                         \"nor\",\"weren't\",\"doesn't\",\"hasn't\",\"haven't\",\"shouldn\",\"mustn't\"] \n",
        "        \n",
        "        self.stop = set([word for word in self.stop if word not in self.not_stopwords])\n",
        "        self.table = str.maketrans({key: None for key in string.punctuation})\n",
        "        self.lemma = WordNetLemmatizer()\n",
        "        \n",
        " \n",
        "  \n",
        "    def remove_numbers(self, text):\n",
        "\n",
        "        try:\n",
        "            return re.sub(r'\\b\\d+(?:\\.\\d+)?\\s+', '', text)\n",
        "        except:\n",
        "            return text\n",
        "\n",
        "    def clean_text(self, x):\n",
        "        x = x.lower()\n",
        "        x = self.remove_numbers(x)\n",
        "        x = [i for i in x.lower().split() if i not in self.stop]\n",
        "        x = \" \".join(x)\n",
        "#         x = re.sub(r\"[^A-Z/a-z0-9(),!?\\'\\`.]\", \" \", x)\n",
        "        x = re.sub((r\"^[\\W]*\"), \"\", x)\n",
        "        x = re.sub((r\"\\s[\\W]\\s\"), \", \", x)\n",
        "        x = [i for i in x.split() if len(i) > 1]\n",
        "        x = \" \".join(x)\n",
        "        x = re.sub(r\"[^A-Z/a-z0-9(),!?\\'\\`.]\", \" \", x)\n",
        "        x = x.translate(self.table)\n",
        "\n",
        "        normalized = \" \".join(self.lemma.lemmatize(word) for word in x.split())\n",
        "        return x\n",
        "    "
      ],
      "metadata": {
        "id": "taewBvbGz3IT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clean_text_ = CleaningText()"
      ],
      "metadata": {
        "id": "J94AQrFk0g2S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clean_text_.clean_text(\"I am Noman khan playing\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "fm1NeJwf0hwp",
        "outputId": "b9b77637-a974-4b50-bd79-0c321f9103cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'noman khan playing'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2kEjT2moxVI"
      },
      "source": [
        "from gensim.similarities import MatrixSimilarity\n",
        "from operator import itemgetter\n",
        "\n",
        "import string\n",
        "import re\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "import string\n",
        "import gensim\n",
        "import operator\n",
        "import re\n",
        "import spacy\n",
        "from spacy.lang.en.stop_words import STOP_WORDS\n",
        "from gensim import corpora\n",
        "from gensim import corpora\n",
        "import nltk\n",
        "\n",
        "\n",
        "data = pd.read_json('/content/drive/MyDrive/Freelancing/Project- 26/All_services_list_ar.json')\n",
        "stop_word_path = \"stop.txt\"\n",
        "class SearchTerm:\n",
        "  def __init__(self):\n",
        "   \n",
        "    #self.spacy_nlp = spacy.load('en_core_web_sm')\n",
        "    #create list of punctuations and stopwords\n",
        "    self.punctuations = string.punctuation\n",
        "    self.stop_words = pd.read_csv(stop_word_path, header=None)\n",
        "    self.stop_words = self.stop_words[0].unique().tolist()\n",
        "    self.clean = CleaningText()\n",
        "\n",
        "\n",
        "  def search_similar_terms(self,search_term):\n",
        "    legal_tfidf_model,legal_lsi_model,legal_lsi_corpus,dictionary =self.get_models(data)\n",
        "\n",
        "    legal_index = MatrixSimilarity(legal_lsi_corpus, num_features = legal_lsi_corpus.num_terms)\n",
        "    query_bow = dictionary.doc2bow(self.tokenizer(search_term))\n",
        "    query_tfidf = legal_tfidf_model[query_bow]\n",
        "    query_lsi = legal_lsi_model[query_tfidf]\n",
        "\n",
        "    legal_index.num_best = 1\n",
        "\n",
        "    legal_list = legal_index[query_lsi]\n",
        "\n",
        "    legal_list.sort(key=itemgetter(1), reverse=True)\n",
        "    legal_names = []\n",
        "\n",
        "    for j, legal in enumerate(legal_list):\n",
        "    \n",
        "        legal_names.append (\n",
        "            {\n",
        "                'Relevance_score': int(round((legal[1] * 100),2)),\n",
        "                'unique_id': data['unique_id'][legal[0]],\n",
        "                'id': data['id'][legal[0]],\n",
        "                'name': data['name'][legal[0]]\n",
        "            }\n",
        "\n",
        "        )\n",
        "        if j == (legal_index.num_best-1):\n",
        "            break\n",
        "\n",
        "    return legal_names\n",
        "\n",
        "  def get_data(self,data):\n",
        "    try:\n",
        "      for index, row in data.iterrows():\n",
        "        description = data['description'][index]\n",
        "        name = data['name'][index]\n",
        "        output = data['output'][index]\n",
        "        eligibility = data['eligibility'][index]\n",
        "        data.loc[index, 'Content'] = name + output + eligibility\n",
        "      return data\n",
        "    except Exception as e:\n",
        "      print(\"There's something while getting data\",e)\n",
        "\n",
        "\n",
        "  def tokenizer(self,sentence):\n",
        "    #remove distracting single quotes\n",
        "    sentence = self.clean.arabic_preprocessing(sentence)\n",
        "    sentence = re.sub('\\'','',sentence)\n",
        "\n",
        "    #remove digits adnd words containing digits\n",
        "    sentence = re.sub('\\w*\\d\\w*','',sentence)\n",
        "\n",
        "    #replace extra spaces with single space\n",
        "    sentence = re.sub(' +',' ',sentence)\n",
        "\n",
        "    #remove unwanted lines starting from special charcters\n",
        "    sentence = re.sub(r'\\n: \\'\\'.*','',sentence)\n",
        "    sentence = re.sub(r'\\n!.*','',sentence)\n",
        "    sentence = re.sub(r'^:\\'\\'.*','',sentence)\n",
        "    \n",
        "    #remove non-breaking new line characters\n",
        "    sentence = re.sub(r'\\n',' ',sentence)\n",
        "    \n",
        "    #remove punctunations\n",
        "    sentence = re.sub(r'[^\\w\\s]',' ',sentence)\n",
        "\n",
        "    tokens = nltk.word_tokenize(sentence)\n",
        "    #return tokens\n",
        "    return tokens\n",
        "  def get_models(self,data):\n",
        "    try:\n",
        "      data['output'] = data['output'].apply(self.clean.cleanhtml)\n",
        "      data = self.get_data(data)\n",
        "      data['content_tokenized'] = data['Content'].map(lambda x: self.tokenizer(x))\n",
        "      legal_content = data['content_tokenized']\n",
        "      dictionary = corpora.Dictionary(legal_content)\n",
        "      stoplist = set('hello and if this can would should could tell ask stop come go')\n",
        "      stop_ids = [dictionary.token2id[stopword] for stopword in stoplist if stopword in dictionary.token2id]\n",
        "      dictionary.filter_tokens(stop_ids)\n",
        "      dict_tokens = [[[dictionary[key], dictionary.token2id[dictionary[key]]] for key, value in dictionary.items() if key <= 50]]\n",
        "      corpus = [dictionary.doc2bow(desc) for desc in legal_content]\n",
        "      word_frequencies = [[(dictionary[id], frequency) for id, frequency in line] for line in corpus[0:3]]\n",
        "      legal_tfidf_model = gensim.models.TfidfModel(corpus, id2word=dictionary)\n",
        "      legal_lsi_model = gensim.models.LsiModel(legal_tfidf_model[corpus], id2word=dictionary, num_topics=300)\n",
        "      gensim.corpora.MmCorpus.serialize('legal_tfidf_model_mm', legal_tfidf_model[corpus])\n",
        "      gensim.corpora.MmCorpus.serialize('legal_lsi_model_mm',legal_lsi_model[legal_tfidf_model[corpus]])\n",
        "      legal_tfidf_corpus = gensim.corpora.MmCorpus('legal_tfidf_model_mm')\n",
        "      legal_lsi_corpus = gensim.corpora.MmCorpus('legal_lsi_model_mm')\n",
        "    \n",
        "      return legal_tfidf_model,legal_lsi_model,legal_lsi_corpus,dictionary\n",
        "    except Exception as e:\n",
        "      print(\"Can't able to execute the model\",e)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "er_1QaFdo5Hy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9daddc62-e372-437d-a428-0f1c1d4febfe"
      },
      "source": [
        "search = SearchTerm()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[2022-04-23 09:28:02,930 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"تجديد تصريح سائق باص مدرسة\"\n",
        "result = search.search_similar_terms(text)\n",
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y5GGZkPnS3EN",
        "outputId": "518d5b89-182e-493c-a119-82e6772ebf7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'Relevance_score': 71,\n",
              "  'id': 3705033,\n",
              "  'name': 'طلب استئجار باص دبي المائي',\n",
              "  'unique_id': 70351}]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test = data[data['id']==3705041]\n",
        "print(test['name'])\n",
        "print(test['description'])\n",
        "print(test['output'])\n",
        "print(test['eligibility'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vqVI2WgQC4zD",
        "outputId": "751125ea-329c-43e6-af52-5d7272fc6e30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "240    طلب إصدار تصريح مزاولة مهنة سائق جديد للنقل ال...\n",
            "Name: name, dtype: object\n",
            "240    تُمكّنك هذه الخدمة من الحصول على تصريح مزاولة ...\n",
            "Name: description, dtype: object\n",
            "240    تصريح مزاولة مهنة سائق للنقل المدرسي.\n",
            "Name: output, dtype: object\n",
            "240    يحقُّ لسائقي المدارس والشركات العاملة في النقل...\n",
            "Name: eligibility, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test1 = data[data['id']==3705033]\n",
        "print(test1['name'])\n",
        "print(test1['description'])\n",
        "print(test1['output'])\n",
        "print(test1['eligibility'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58XhpJDLFcnd",
        "outputId": "55ebdb4a-4f50-4c5d-c45e-b2c99748778e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "164    طلب استئجار باص دبي المائي\n",
            "Name: name, dtype: object\n",
            "164    تُمكّنك هذه الخدمة من استئجار الباص المائي. هن...\n",
            "Name: description, dtype: object\n",
            "164    استئجار باص دبي المائي.\n",
            "Name: output, dtype: object\n",
            "164    يحقُّ للأفراد والشركات الحصول على هذه الخدمة.\n",
            "Name: eligibility, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sUSTfn1pCoL2",
        "outputId": "204b8e26-72d0-4573-a125-90570f0a6785"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'Relevance_score': 71,\n",
              "  'id': 3705033,\n",
              "  'name': 'طلب استئجار باص دبي المائي',\n",
              "  'unique_id': 70351},\n",
              " {'Relevance_score': 60,\n",
              "  'id': 3705027,\n",
              "  'name': 'التنقل بباص دبي المائي - العبرات المكيفة',\n",
              "  'unique_id': 70350},\n",
              " {'Relevance_score': 36,\n",
              "  'id': 3704704,\n",
              "  'name': 'طلب تجديد تصريح سائق مهني',\n",
              "  'unique_id': 70217}]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result[0]['Relevance_score']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mKfuFdPnhzQ6",
        "outputId": "6a711ca3-13e3-4634-c4ff-fa853b14066b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "71"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9TxiJ62Qf3R_",
        "outputId": "08707122-714e-49eb-b8ef-11f8c7047030"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2GLAAwdnge6u",
        "outputId": "d3209588-96c0-46e3-9433-92fed1c482b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Relevance_score': 71,\n",
              " 'id': 3705033,\n",
              " 'name': 'طلب استئجار باص دبي المائي',\n",
              " 'unique_id': 70351}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "int(result[0]['id'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQKIKfbPoAnR",
        "outputId": "d8a9e03a-efe7-420c-f1ca-3000a977f76a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3705033"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test = [result[0]]"
      ],
      "metadata": {
        "id": "WKTRI1cjgodF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OAcSBmjngrnw",
        "outputId": "de50a286-020e-4a5b-a617-0a34608e5383"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'Relevance_score': 71,\n",
              "  'id': 3705033,\n",
              "  'name': 'طلب استئجار باص دبي المائي',\n",
              "  'unique_id': 70351}]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "books = [\n",
        "    {'id': 0,\n",
        "     'title': 'A Fire Upon the Deep',\n",
        "     'author': 'Vernor Vinge',\n",
        "     'first_sentence': 'The coldsleep itself was dreamless.',\n",
        "     'year_published': '1992'},\n",
        "    {'id': 1,\n",
        "     'title': 'The Ones Who Walk Away From Omelas',\n",
        "     'author': 'Ursula K. Le Guin',\n",
        "     'first_sentence': 'With a clamor of bells that set the swallows soaring, the Festival of Summer came to the city Omelas, bright-towered by the sea.',\n",
        "     'published': '1973'},\n",
        "    {'id': 2,\n",
        "     'title': 'Dhalgren',\n",
        "     'author': 'Samuel R. Delany',\n",
        "     'first_sentence': 'to wound the autumnal city.',\n",
        "     'published': '1975'}\n",
        "]"
      ],
      "metadata": {
        "id": "ndFWjDzEfuFT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(books)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rnOnWbs4fxd4",
        "outputId": "be3c85b9-272f-476b-a7e4-33e3cb797e1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tcUaZZGefumW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(result))\n",
        "print(type(result[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WN-Jy9Y36mwi",
        "outputId": "6c56a7f0-b6e9-49d0-c958-2bd2f7165ec3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'list'>\n",
            "<class 'dict'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dict_obj = {}\n",
        "dict_obj[\"result_1\"] = result[0]\n",
        "dict_obj[\"result_2\"] = result[0]\n",
        "dict_obj[\"result_3\"] = result[0]\n",
        "# for i in range(len(result)):\n",
        "#   print(i)\n",
        "#   print(result[i])\n",
        "#   dict_obj[\"color\"] = result[i]"
      ],
      "metadata": {
        "id": "aC0jIbMFR0eD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dict_obj"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SFKergcMTkPh",
        "outputId": "aa8b0076-f26a-43bf-fb44-a8ea6fe6cdf0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'result_1': {'Relevance_score': 71,\n",
              "  'id': 3705033,\n",
              "  'name': 'طلب استئجار باص دبي المائي',\n",
              "  'unique_id': 70351},\n",
              " 'result_2': {'Relevance_score': 71,\n",
              "  'id': 3705033,\n",
              "  'name': 'طلب استئجار باص دبي المائي',\n",
              "  'unique_id': 70351},\n",
              " 'result_3': {'Relevance_score': 71,\n",
              "  'id': 3705033,\n",
              "  'name': 'طلب استئجار باص دبي المائي',\n",
              "  'unique_id': 70351}}"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from Search import SearchTerm\n",
        "test = SearchTerm()"
      ],
      "metadata": {
        "id": "ETKL9dKDeRhY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "outputId": "99650f1a-8ef6-4dae-e5f0-f784bd96ded7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-967cd6e51f3f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mSearch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSearchTerm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSearchTerm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'Search'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = test.search_similar_terms(\"طلب إصدار بدل فاقد أو تالف لتصريح تعلم القيادة\")\n",
        "result"
      ],
      "metadata": {
        "id": "Zbg8HoiZhSwT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile test.py\n",
        "from flask import Flask\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "\n",
        "@app.route('/')\n",
        "def hello():\n",
        "    return 'Hello, World!'"
      ],
      "metadata": {
        "id": "kbo4nNgRmKNd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "from flask import Flask, jsonify, request\n",
        "import traceback\n",
        "from flask import Flask, render_template , request \n",
        "import os\n",
        "\n",
        "from Search import SearchTerm\n",
        "test = SearchTerm()\n",
        "\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "dict_obj = {}\n",
        "\n",
        "\n",
        "@app.route('/predict',methods=['GET','POST'])\n",
        "def classify_review():\n",
        "  try:\n",
        "    search_term = request.args.get('text', type=None)\n",
        "    result = test.search_similar_terms(search_term)\n",
        "    dict_obj[\"result_1\"] = result[0]\n",
        "    dict_obj[\"result_2\"] = result[0]\n",
        "    dict_obj[\"result_3\"] = result[0]\n",
        "    return jsonify(dict_obj)\n",
        "  except Exception as e:\n",
        "    return jsonify({'error':e})\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # This is used when running locally only. When deploying to Google Cloud\n",
        "    # Run, a webserver process such as Gunicorn will serve the app.\n",
        "\n",
        "    app.run(debug=False, host=\"0.0.0.0\", port=int(os.environ.get(\"PORT\", 8080)))\n",
        " \n"
      ],
      "metadata": {
        "id": "p7JNcP5UaunH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from flask import Flask, jsonify, request\n",
        "request.args.get()"
      ],
      "metadata": {
        "id": "HCsATCeIdL_w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# flask_ngrok_example.py\n",
        "from flask import Flask\n",
        "from flask_ngrok import run_with_ngrok\n",
        "\n",
        "app = Flask(__name__)\n",
        "run_with_ngrok(app)  # Start ngrok when app is run\n",
        "\n",
        "@app.route(\"/\")\n",
        "def hello():\n",
        "    return \"Hello World!\"\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run()"
      ],
      "metadata": {
        "id": "wDdaHuKOmQfn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}